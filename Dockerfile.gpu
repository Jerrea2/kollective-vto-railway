# syntax=docker/dockerfile:1.6

############################
# STAGE 1 — Bake SDXL (Silent)
############################
FROM python:3.10-slim AS sdxl_bake

ARG SDXL_REPO=stabilityai/stable-diffusion-xl-base-1.0
ARG SDXL_REVISION=main
ARG SDXL_DIR=/models/sdxl

RUN apt-get update && apt-get install -y --no-install-recommends \
    git ca-certificates \
    && rm -rf /var/lib/apt/lists/*

RUN pip install --no-cache-dir huggingface_hub==0.25.2

# Create silent bake script
RUN echo "import os" > /bake_sdxl.py && \
    echo "from huggingface_hub import snapshot_download" >> /bake_sdxl.py && \
    echo "repo_id=os.environ['SDXL_REPO']" >> /bake_sdxl.py && \
    echo "revision=os.environ['SDXL_REVISION']" >> /bake_sdxl.py && \
    echo "local_dir=os.environ['SDXL_DIR']" >> /bake_sdxl.py && \
    echo "token=os.environ['HF_TOKEN']" >> /bake_sdxl.py && \
    echo "snapshot_download(repo_id=repo_id,revision=revision,local_dir=local_dir,token=token,local_dir_use_symlinks=False,resume_download=True,max_workers=4)" >> /bake_sdxl.py && \
    echo "print('SDXL bake complete')" >> /bake_sdxl.py

RUN --mount=type=secret,id=HF_TOKEN \
    export HF_TOKEN=$(cat /run/secrets/HF_TOKEN) && \
    mkdir -p ${SDXL_DIR} && \
    python /bake_sdxl.py

RUN test -f ${SDXL_DIR}/model_index.json

############################
# STAGE 2 — Runtime
############################
FROM nvidia/cuda:11.8.0-runtime-ubuntu22.04

ENV DEBIAN_FRONTEND=noninteractive

RUN apt-get update && apt-get install -y \
    python3.10 \
    python3-pip \
    git \
    curl \
    ca-certificates \
    && rm -rf /var/lib/apt/lists/*

RUN ln -sf /usr/bin/python3.10 /usr/bin/python

WORKDIR /app

COPY --from=sdxl_bake /models/sdxl /models/sdxl

ENV HF_HUB_OFFLINE=1
ENV TRANSFORMERS_OFFLINE=1
ENV HF_DATASETS_OFFLINE=1
ENV HF_HUB_DISABLE_TELEMETRY=1

COPY requirements.txt /app/requirements.txt
RUN pip install --no-cache-dir -r /app/requirements.txt

COPY src /app/src

ENV PYTHONUNBUFFERED=1
ENV PRETRAINED_MODEL_PATH=/models/sdxl

EXPOSE 8000

CMD ["python","-m","uvicorn","src.inference:app","--host","0.0.0.0","--port","8000"]
